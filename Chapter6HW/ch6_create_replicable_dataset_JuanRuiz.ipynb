{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saves the Replicable Dataset of Tweet ID's\n",
    "#Set new filename to store replicable dataset\n",
    "import os\n",
    "input_filename = os.path.join(os.path.expanduser(\"~\"), \"OneDrive\", \"Desktop\", \"Data Mining\", \"Chapter6HW\", \"Data\", \"Datasets\", \"twitter\", \"python_tweets.json\")\n",
    "labels_filename = os.path.join(os.path.expanduser(\"~\"), \"OneDrive\", \"Desktop\", \"Data Mining\", \"Chapter6HW\", \"Data\", \"Datasets\", \"twitter\", \"python_classes.json\")\n",
    "replicable_dataset = os.path.join(os.path.expanduser(\"~\"), \"OneDrive\", \"Desktop\", \"Data Mining\", \"Chapter6HW\", \"Data\", \"Datasets\", \"twitter\", \"replicable_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load tweets and labels as before\n",
    "import json\n",
    "tweets = []\n",
    "with open(input_filename) as inf:\n",
    "    for line in inf:\n",
    "        if len(line.strip()) == 0:\n",
    "            continue\n",
    "        tweets.append(json.loads(line))\n",
    "if os.path.exists(labels_filename):\n",
    "    with open(labels_filename) as inf:\n",
    "        labels = json.load(inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d948a5dc1b6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Creates dataset by looping over tweets and labels simultaneously and saving the entries in a list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#Labels first will load enough tweets for labels we created, like partially classified data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "#Creates dataset by looping over tweets and labels simultaneously and saving the entries in a list\n",
    "#Labels first will load enough tweets for labels we created, like partially classified data\n",
    "dataset = [(tweet['id'], label) for label, tweet in zip(labels, tweets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays the lengths of each data value\n",
    "len(dataset), len(tweets), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the results in the file\n",
    "with open(replicable_dataset, 'w') as outf:\n",
    "    json.dump(dataset, outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
